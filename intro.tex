The strength of lazy functional programming languages is the freedom they
give the programmer to focus on correctness instead of operational details. In a
strict language, the programmer specifies exactly what code should be run. In a
lazy language, only the code necessary to compute a result is run. As a result
of this freedom from operational concerns, there are two properties that lazy
functional programers tend to have. First, they reason about the correctness of
their code to a degree seen almost nowhere else in the programming community.
Second, they rely on the compilers for these languages to generate efficient
code in a way that programmers of strict languages don't.  Essentially, they are
leaving more operational decisions up to the compiler, and focusing their energy
more on the correctness of their code. 

It is for this reason that we compiler implementors must take great care in the
design of our compilers for lazy languages. We must have compilers that are
efficient: our programmers are relying particularly heavily on our ability to
generate efficient code. We also must ensure that our compilers are correct:
because the programmers are free to reason about the correctness of their code,
we must ensure that this additional reasoning is not invalidated by bugs in the
compiler. 

This dissertation presents a tool for attaining these two goals: a novel
technique for implementing lazy semantics using shared environments, formalized
as the \ce machine. Essentially, the \ce machine repurposes shared environments
to share the results of computation. The insight of this dissertation is that
this approach leads to a simple, efficient compiler. I exploit the efficiency of
the approach by implementing a native code compiler with good performance. This
addresses the goal of efficient compilation. To verify correctness, I take
advantage simplicity of the approach to ease the proof burden. These two
implementations provide ample evidence that the \ce machine has the properties
we want, and is therefore a powerful tool for implementing lazy functional
programming languages.

\section{Outline}

This dissertation is organized into six chapters. In this chapter, I provide
an introduction to the dissertation, including an outline of the structure,
instructions for access to artifacts and reproduction of results, and an
overview of the contributions. In Chapter~\ref{chap:background}, I provide
necessary background for understanding the dissertation, as well as further
discussion of motivation. In Chapter~\ref{chap:ce}  In Chapter~\ref{chap:cem},
I describe the implementation of a native code compiler based on the \ce
machine, and analyze and discuss its performance. In
Chapter~\ref{chap:verified}, I present the verified compiler, discussing the
structure of the compiler and proofs. Finally, in Chapter~\ref{chap:conclusion},
I discuss threats to validity, future work, and conclusions. We then use
appendices to give further implementation details, both for the native code
compiler and the verified compiler. In the case of the native code compiler, our
hope is to share some of the other interesting properties of the implementation.
For the verified compiler, the purpose of the appendix is to give the reader a
more full understanding of the structure and definitions involved in the proofs,
so that she may convince herself that they are correct.

\section{Reproducibility and Artifacts}

The implementations presented in this dissertation are available for download to
allow the reader to reproduce any claims made. All of the software is bundled as
a single tarball at \url{http://cs.unm.edu/\textasciitilde stelleg/cem.tgz}.
Instructions are included for building, running, and proof-checking the code.
For performance results, the hardware and operating system are listed in
Chapter~\ref{chap:cem}. In addition to the above tarball, each implementation has been
continued to be developed at \url{https://github.com/stelleg/cem} and
\url{https://github.com/stelleg/cem\_coq}. Finally, there is a simpler native
code compiler for pedagogical purposes available at
\url{https://github.com/stelleg/cem\_pearl}. 

\section{Call-by-Need}

Because this work is focused on implementing call-by-need semantics, it is worth
spending some time discussing why call-by-need semantics are important. That
said, the purpose of this dissertation is not to justify the existence of
call-by-need semantics. For a more technical coverage of the topic, including
definitions, see Section~\ref{sec:eval_strat}, which defines and contrasts
different evaluation strategies.

One easy argument for the importance of call-by-need is that it underlies the
widely used programming language Haskell. Technically, Haskell is a non-strict
language.  This implies that both call-by-name and call-by-need are valid
implementation strategies. In practice, there are some situations when one would
prefer call-by-name, namely, when storing an intermediate value is more
expensive than re-computing it. These cases are not limited to call-by-need;
call-by-value suffers the same issue.  This implies that in theory, Haskell
could switch between call-by-name and call-by-value depending on the situation.
In practice, GHC effectively always chooses call-by-need, sometimes even
performing compile-time transformations that increase memoization
\cite{jones96floating}.  

Even amongst the Haskell community, the advantages and disadvantages of
non-strict evaluation are hotly debated. For example, there exist both
strictness annotations, and even strict-by-default variants of Haskell. There
are real reasons for preferring strict evaluation in some contexts. In
particular, reasoning about time and space requirements for lazy programs is
notoriously difficult.  

The advantages of non-strict semantics often show up especially when attempting
to write high level, composable abstractions. This is a strong argument for code
re-use advantages in non-strict languages: by using laziness, one avoids work
and non-termination where possible without additional programmer effort.

There are also well-known cases of when composing lazy programs can result in
better asymtotics than strict composition. Consider the well-known case for
finding the minimal value in a list. 
\begin{verbatim}
  take 1 . sort
\end{verbatim}
With lazy semantics, this can result in an $O(n)$ implementation, where the
strict implementation of compose will always result in a $O(n \log n)$
implementation. This kind of asymptotic improvement is a direct result of the
efficiencies gained by avoiding eager work. 

\section{Retrospective}

As with any sufficiently large effort, there are places where, if I were to
start over, I would do things differently. A possible candidate for this
re-writing of history would be \emph{starting} with a verified compiler, so that
the native code compiler itself would be verified. While noble in nature, this
would be a daunting task. Implementing a full native code compiler is a
challenge in itself, but specifying, implementing, and verifying a native code
compiler is a massive undertaking. That said, it would likely have worked to
verify and export into Haskell fragments of the native code compiler. While this
would certainly have been feasible, it would have made modification more
difficult. For example, multiple times through the implementation process, the
core language was extended. Making such core changes in the presence of proofs
of correctness would make for a painful process, something that would have
slowed down valuable time experimenting with the implementation. Overall, I am
content with the approach of this dissertation: two separate compilers, with one
focused on performance and extensibility and the other focused on correctness. I
leave combining the two for future work, as I discuss further in
Section~\ref{sec:future}.

\section{Contributions}

There are three primary contributions of this dissertation.

\begin{itemize}
\item A novel technique for implementing call-by-need semantics using shared
environments. The technique is formalized in the \ce machine, defined with both
a big and small-step semantics.

\item A full native code compiler from a simple lazy functional language with
literals and primitive operations to x86\_64 machine code. The implementation
follows naturally from the definition of the \ce machine. I show that the
compiler performs comparably to the state of the art on a number of benchmarks.
This implementation and its analysis provide evidence supporting the thesis that
shared-environment call-by-need has novel efficiencies.

\item A verified compiler that compiles call-by-need lambda calculus to a simple
instruction machine, along with a specification of correctness and a proof that
the compiler adheres to that specification. The compiler is implemented and the
proofs checked in Coq, formalizing the \ce semantics in the process. This is the
first verified compiler of a call-by-need semantics. This implementation and
mechanized proof provides evidence for the thesis that the simplicity of \ce
implementations lends itself to formal verification
\end{itemize}

Combined, these contributions support the core thesis of this dissertation: that
shared-environment call-by-need has valuable contributions to make to the study
and implementation of call-by-need compilers. Smaller, more
implementation-specific contributions are enumerated in Chapters~\ref{chap:cem}
and~\ref{chap:verified}. 
