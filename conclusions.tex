This dissertation is a thorough investigation of a shared-environment approach
to implementing call-by-need semantics. Chapter~\ref{chap:cem} investigated the
runtime efficiency advantages by implementing a simple native code compiler.
Despite the compiler's lack of optimization framework, it was often competitive
with the state of the art. From this, the conclusion is that this approach is a
promising abstract machine for real-world compilers. Chapter~\ref{chap:verified}
showed how to use the simplicity of the implementation to effectively reason
formally about its correctness. While it was a significant undertaking, the
success of the verified compiler provides strong evidence that the simplicity of
the machine is a valuable property, and that property can be further exploited
in future work.

For the rest of this Chapter, we take a retrospective look at the work done for
the dissertation, discussing both what worked well and what didn't. The hope is that
this deeper dive into the challenges and successes throughout the dissertation
can better inform future work, both work that uses the \ce machine directly, and
work that might take a different approach, but with similar goals. While some of
what is discussed in this section has been covered in previous Chapters, we try
and address big-picture conclusions here, accumulating the lessons learned along
the way. In addition, through discussions with other experts and through further
introspection, more conclusions and lessons learned have been discovered, and we
use this section to bring those to light. 

More specifically, this chapter attempts to do a few things. First, it
summarizes the theses and conclusions of the dissertation. Second, it summarizes
and addresses the threats to validity of the conclusions presented.  Largely
motivated by addressing these threats to validity, it then discusses future
directions enabled by this work. 

\section{Threats to Validity}

This section attempts to summarize and address the most pressing threats to the
validity to the theses and conclusions discussed in this dissertation. While it
attempts to enumerate the most pressing threats, any list of this nature will be
incomplete, and therefore the goal is not to create a complete list. Instead,
the aim of the section is simply to convey that possible criticisms have been
seriously considered. Note that Chapters~\ref{chap:cem} and \ref{chap:verified}
have chapter-specific threats to validity, so in this section we instead focus
on more general threats to validity. 

The first, and most glaring, is that the verified compiler makes no claims about
the behaviour of the compiled code in the case of non-termination in the source
semantics. One point to make is that even if we accept that this work only
applies to total languages, and they do exist (Agda, Coq, STLC,
etc.)~\cite{turner2004total}, then in the context of those languages, this is a
complete verified compiler. 

Some readers may be inclined to dismiss a compiler, like the one presented here,
that doesn't implement recursion and algebraic data types explicitly. A
tangential goal of this dissertation is to open the reader to the possibility
that those are not necessary for high performance code. Removing them certainly
makes formal reasoning simpler, something that hopefully the reader is convinced
is an important property for a compiler to have.  

\section{Future Work}\label{sec:future}

While Chapters~\ref{chap:cem} and \ref{chap:verified} have sections dedicated to
future work specific to their topics, we expand on those here, discussing future
work that could combine the approaches of both efforts. 

The most obvious one would be to combine the efforts. By extracting the Coq
implementation of the compiler into Haskell, the language that the native code
compiler is implemented in, we would attain a verified fragment of a true native
code compiler. One could then work towards extending the proof to cover more of
the implementation over time. When combined with the possibility of implementing
a full Haskell compiler using the native code compiler in this work, we have a
viable path towards a high performance, fully verified compiler for Haskell. 

This approach neglects the fact that there are many cases where GHC
significantly outperforms the native code compiler in its current form. Recent
work on verified transformations and optimizations, when combined with our
verified compiler, could result in a verified compiler that is actually
competitive with GHC in performance, likely outperforming it in some cases due
to lightweight closure creation enabled by the \ce machine. In a sense, this
would be a natural next step to the existing type-safe core language of GHC:
instead of just ensuring that transformations are type-safe, we could have a
compiler that ensures that they are correct.

While discussed briefly in the previous chapters, one exciting area for future
work is reasoning formally about performance. Reasoning about memory use of lazy
functional programs is notoriously hard, so any help that the compiler can
provide is extremely valuable. Unfortunately, heuristic approaches interacting
with the many optimizations that exist already can lead to extreme difficulty in
reasoning about memory consumption of a source program. We hope that in
combination with future language tools, one could use the simplicity of the
compiler presented here to better reason about time and space efficiencies, and
help ensure that the compiler makes better decisions about how to preserve
and/or improve time and space requirements. The lack of many intermediate
representations makes this compiler an ideal target for such reasoning.

\section{Theses Review}

There are two theses presented in this dissertation. First, shared-environments
efficiently implement call-by-need semantics, as described by the \ce machine.
This thesis is described in detail in Chapter~\ref{chap:cem}. The conclusion of
this chapter is that there are clear efficiencies gained and efficiencies lost
with the shared environment approach. In particular, the efficiency gained by
reduced thunk creation overhead enabled more efficient lambda calculus
evaluation. 

The primary conclusion for this thesis is that this is a good default behavior,
but one that should be optimized away. Consider the analogue of strictness
analysis. The idea behind strictness analyses and transforms is that laziness is
a good default, but one that should be replaced with eager evaluation for
efficiency where possible. In the same way, lazy thunk creation is a good
default, but one that should be replaced with an optimized flat environment
closure where necessary for efficiency reasons. In terms of cheap to create vs. 
efficient to execute, we can think of the shared-environment closure as the most
extremely cheap to create, at the cost of efficiency to execute, whereas a
just-in-time compiled closure specialized on its values might be at the other
extreme: expensive to create, but efficient to execute. 

The second thesis of the dissertation is that the simplicity of the compiler
that implements the \ce machine lends itself to formal reasoning. This thesis is
described in detail in Chapter~\ref{chap:verified}. The evidence for this thesis
is provided in the form of a verified compiler. The implementation of the first
verified compiler of a call-by-need semantics provides compelling support for
this thesis. 

The conclusion for this thesis is therefore that yes, the simplicity of the
compiler indeed lends itself to formal reasoning. That said, there are still
many open questions. For example, many of the proofs are excruciatingly complex.
It is therefore not at all clear that the structure of the compiler and proofs
is \emph{the best possible}. Indeed, we expect there is room for improvement,
particularly in the implementation of the proofs. 

\section{Conclusion}

This dissertation has presented a novel technique for implementing call-by-need
semantics using shared environments, the \ce machine, along with a pair of
compilers that provide evidence for the primary thesis of this dissertation: the
\ce machine lends itself to high performance, easy to reason about compilers. 

Given that these are desirable properties for a compiler to have, then we must
conclude that the \ce machine and the compilers it enables are valuable tools
for implementing call-by-need. My hope is that if the compilers developed in
this dissertation are not used directly in future compilers for lazy
languages, the ideas underlying them will be. 


