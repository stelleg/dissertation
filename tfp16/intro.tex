Existing implementations of call-by-need take care in \emph{packaging} a delayed
computation, or \emph{thunk}, by building a closure with an array that contains
the bindings of all free variables \cite{jonesstg,boquist1997grin}. The overhead
induced by this operation is well known, and is one reason existing
implementations avoid thunks wherever possible \cite{johnsson1984efficient}. The
key insight of our Cactus Environment (\ce) Machine is that this overhead can be
minimized by only recording a location in a shared environment.

As an example, consider the application $f \; e$. In existing call-by-need
implementations, e.g., the STG machine\cite{jonesstg}, a closure with a flat
environment will be constructed for $e$.  Doing so incurs a time and memory cost
proportional to the number of free variables of $e$. \footnote{In some
implementations, these are lambda-lifted to be formal parameters, but the
principle is the same.} We minimize this packaging cost by recording a
location in a shared environment, which requires only two
machine words (and two instructions) for the thunk: one for the code pointer,
and one for the environment pointer. One way to think about the approach is that
it is \emph{lazier} about lazy evaluation: in the case that $e$ is unneeded, the
work to package it in a thunk is entirely wasted. In the spirit of lazy
evaluation, we attempt to minimize this potentially unnecessary work.  

In this chapter we present a simple implementation of the \ce machine that
compiles a simple lazy functional language to x86\_64 assembly. In addition, it
presents a preliminary evaluation that shows performance comparable to existing
implementations (Sections~\ref{sec:impl} and~\ref{sec:eval}). 

We describe a straightforward
implementation of \ce in Section~\ref{sec:impl}, extended with machine literals
and primitive operations, and compiling directly to native code. We evaluate the
implementation in Section~\ref{sec:eval}, showing that it is capable of
performing comparably to existing implementations despite lacking several common
optimizations, and we discuss the results. We discuss related work, the
limitations of our approach, and some ideas for future work in
Section~\ref{sec:disc}.
